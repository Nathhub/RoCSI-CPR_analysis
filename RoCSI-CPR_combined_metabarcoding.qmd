---
title: "AtlantECO RoCSI-CPR eDNA Metabarcoding ‚Äî Combined COI & 18S Report"
author: "Nathan Hubot"
format:
  html:
    toc: true
    toc-depth: 2
    theme: cosmo
    code-fold: true
editor: source
---

# üß¨ Overview of Sequencing & Experimental Design

This report summarises the **two metabarcoding workflows** applied to the RoCSI-CPR eDNA samples:

-   **18S rRNA V9 region** (targeting phytoplankton)
-   **COI mitochondrial region** (targeting zooplankton)

Both datasets were sequenced at the\
**Centre for Genomic Research (CGR), University of Liverpool.**

## üìä Sequencing Summary

| Feature | **18S rRNA V9** | **COI (metazoans)** |
|-----------------|-------------------------|-------------------------------|
| **SSP ID** | [SSP202877](https://cgr.liv.ac.uk/illum/SSP202877_b388934ddf413642/) | [SSP200993](https://cgr.liv.ac.uk/illum/SSP200993_bbba6061877a5e12) |
| **Purchase order** | 203631529 | P10817-5 |
| **Sequencing platform** | Illumina MiSeq v2 (2√ó150 bp) | Illumina MiSeq v2 (2√ó250 bp) |
| **Target region** | 18S V9 (1389F‚Äì1510R) | COI Leray fragment (m1COIintF‚ÄìjgHCO2198) |
| **Expected amplicon size** | \~121 bp | \~313 bp |
| **Raw read depth (mean)** | \~150k | \~200k |
| **Pre-trimming QC** | Cutadapt v4.5 | Cutadapt v1.2.1 + Sickle v1.200 |
| **Downstream processing** | Cutadapt ‚Üí DADA2 ‚Üí MZG 18S | Cutadapt ‚Üí DADA2 ‚Üí MZG COI |

------------------------------------------------------------------------

# üß¨ Primer Sets (with CGR Overhangs)

## 18S V9 Primers

-   **Forward:**\
    5‚Ä≤ [ACACTCTTTCCCTACACGACGCTCTTCCGATCTNNNNN]{style="color:#2E86C1;font-weight:bold;"}\
    [TTGTACACACCGCCC]{style="color:#C0392B;font-weight:bold;"} 3‚Ä≤\
    *(CGR overhang + spacer in blue; 18S primer in red)*

-   **Reverse:**\
    5‚Ä≤ [GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT]{style="color:#2E86C1;font-weight:bold;"}\
    [CCTTCYGCAGGTTCACCTAC]{style="color:#C0392B;font-weight:bold;"} 3‚Ä≤

------------------------------------------------------------------------

## COI Primers

-   **Forward:**\
    5‚Ä≤ [ACACTCTTTCCCTACACGACGCTCTTCCGATCTNNNNN]{style="color:#2E86C1;font-weight:bold;"}\
    [GGWACWGGWTGAACWGTWTAYCCYCC]{style="color:#C0392B;font-weight:bold;"} 3‚Ä≤\
    *(m1COIintF)*

-   **Reverse:**\
    5‚Ä≤ [GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT]{style="color:#2E86C1;font-weight:bold;"}\
    [TAIACYTCIGGRTGICCRAARAAYCA]{style="color:#C0392B;font-weight:bold;"} 3‚Ä≤\
    *(jgHCO2198)*

------------------------------------------------------------------------

# üîß Bioinformatic Workflow Overview

Both markers follow the same general pipeline:

1.  **Primer removal** (Cutadapt)\
2.  **Quality filtering** (DADA2)\
3.  **Error learning and denoising** (DADA2)\
4.  **Read merging** (DADA2)\
5.  **Chimera removal** (DADA2)\
6.  **Taxonomic assignment: ** (DADA2)
    -   18S ‚Üí *MZG 18S ‚ÄúAll Microbes + Protists‚Äù, Mode-A* reference database\
    -   COI ‚Üí *MZG COI ‚ÄúAll Invertebrates‚Äù, Mode-A* reference database

For each step, differences between the two pipelines are shown.

------------------------------------------------------------------------

# 1Ô∏è‚É£ Primer Removal with Cutadapt

### üîπ Summary of Cutadapt parameters used

| Parameter | **18S** | **COI** |
|--------------------------|-----------------------|-----------------------|
| Forward primer (`-g`) | TTGTACACACCGCCC | GGWACWGGWTGAACWGTWTAYCCYCC |
| Reverse primer (`-G`) | CCTTCYGCAGGTTCACCTAC | TANACYTCNGGRTGNCCRAARAAYCA |
| `--match-read-wildcards` | ‚úîÔ∏è | ‚úîÔ∏è |
| Minimum overlap | **10** | **20** |
| Max error rate (`-e`) | **0.15** | **0.20** |
| `--discard-untrimmed` | ‚úîÔ∏è | ‚úîÔ∏è |
| `--minimum-length` | 80 bp | 200 bp |
| Pre-processing by CGR | Adapters trimmed via Cutadapt 4.5 | Adapters trimmed (Cutadapt v1.2.1) + Sickle quality filtering |

------------------------------------------------------------------------

### üîπ Unified Cutadapt description

Both datasets used a looping bash command of the form:

``` bash

cutadapt\
  -g <forward_primer> \
  -G <reverse_primer> \
  --match-read-wildcards \
  --overlap <OV> \
  -e <ERROR> \
  --pair-filter=both \
  --discard-untrimmed \
  --cores=0 \
  -o $out1 -p $out2 \
  $f $r

```
Where <OV> and <ERROR> differ between markers (see table above).

# 2Ô∏è‚É£ DADA2 Processing

### üîπ Summary of Cutadapt parameters used

| Parameters                | **18S**    | **COI**                             |
| ------------------------- | ---------- | ----------------------------------- |
| `truncLen`                | c(130,120) | c(210,210)                          |
| `maxEE`                   | c(2,3)     | c(2,3)                              |
| `minLen`                  | 80         | 200                                 |
| `minOverlap` (mergePairs) | 30         | 90                                  |
| Ref database              | MZG 18S    | MZG COI                             |

::: {.callout-note title="MZG Reference databases"}
| Marker  | Database                               | Notes                                        |
| ------- | -------------------------------------- | -------------------------------------------- |
| **18S** | `MZGdada2-18s__T2000000__o00__A.fastq` | phytoplankton --> "All Microbes + Protists", mode-A    |
| **COI** | `MZGdada2-coi__T4000000__o00__A.fastq` | zooplankton --> ‚ÄúAll invertebrates‚Äù, mode-A          |
source: https://metazoogene.org/mzgdb/atlas/html-src/data__T4000000__o00.html
:::

### üîπ Unified DADA2 description

Both datasets were processed with the standard DADA2 workflow:

``` r

# Filtering and trimming (R1/R2 after cutadapt)
filtered_out <- filterAndTrim(
  fwd  = forward_reads,
  filt = filtered_forward_reads,
  rev  = reverse_reads,
  filt.rev = filtered_reverse_reads,
  truncLen  = <MARKER_SPECIFIC>,   # see table above
  maxEE     = c(2, 3),             # expected errors (stricter for R1)
  maxN      = 0,                   # discard reads with Ns
  rm.phix   = TRUE,                # remove PhiX reads
  minLen    = <MINLEN>,            # marker-specific minimum length
  multithread = TRUE
)

# Error learning
errF <- learnErrors(filtered_forward_reads, multithread=TRUE)
errR <- learnErrors(filtered_reverse_reads, multithread=TRUE)

# Dereplication
derepF <- derepFastq(filtered_forward_reads)
derepR <- derepFastq(filtered_reverse_reads)

# ASV inference
dadaF <- dada(derepF, err=errF, pool="pseudo")
dadaR <- dada(derepR, err=errR, pool="pseudo")

# Merging
merged <- mergePairs(dadaF, derepF, dadaR, derepR,
                     minOverlap = <MARKER_SPECIFIC>,
                     trimOverhang = TRUE)

# ASV table
seqtab <- makeSequenceTable(merged)

# Chimera removal
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus")

# Taxonomic Assignment
taxa <- assignTaxonomy(
  seqtab.nochim,
  refFasta = <REF_FASTA>,
  multithread = TRUE
)

```

::: {.callout-note title="Note"}
For 18S, shorter reads (150 bp) and a very short amplicon (~121 bp) justify relatively short truncLen (130, 120) and minLen = 80.
For COI, the longer amplicon fragment (~313 bp) and 2√ó250 bp reads allow more aggressive truncation (210, 210) with large overlap (90) and a higher minLen = 200 to remove spurious short fragments.
:::

# üîç Read Tracking Summary

The following table summarizes read counts at each step of the DADA2 pipeline:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(readr)
library(knitr)
library(kableExtra)

# Load the data
df <- read_csv("data/DADA2_counts_table.csv")

# Rename columns to avoid ...2 suffix
colnames(df) <- c("sample",
                  "input", "filtered", "nonchim", "reads_retained (%)",
                  "input", "filtered", "nonchim", "reads_retained (%)")

# Create a styled table with group headers
kable(df, format = "html", caption = "DADA2 Counts for 18S and COI") %>%
  add_header_above(c(" " = 1, "18S" = 4, "COI" = 4)) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

::: {.callout-note title="Negative Controls"}
The **No-Template Control (NTC)** and **Extraction Blank** samples in the 18S dataset did not pass the initial **DADA2 filtering step**, resulting in zero retained reads after quality filtering.\
Consequently, these controls were **excluded from downstream analysis** (denoising, merging, and taxonomy assignment).

Their exclusion is consistent with expectations for negative controls, indicating the absence of detectable contamination above sequencing background levels.
:::

::: {.callout-note}
### üí¨ Discussion ‚Äî reads retained

The proportion of reads that were kept following the DADA2 pipeline is good: **84%** and **91%** for ***18S** and **COI**, respectively. For 18S, samples 12 and 13 lost more then the rest: **53%** and **60%**, respectively.

:::

## üßÆ Next Steps

At this stage, for each of the datasets/molecular markers, we have:

  - An **OTU abundance table** (`seqtab.nochim`)  
  - A **taxonomy table** (`taxa`)  

These files (provided) can be imported into **R** using the  **[phyloseq](https://www.bioconductor.org/packages/release/bioc/html/phyloseq.html)** package downstream analysis and visualization.

